# Pitagora Meetup 2024-01

## æ¦‚è¦

- æ—¥æ™‚ï¼š 2024å¹´1æœˆ11æ—¥ï¼ˆæœ¨ï¼‰ 13:00 ã€œ 18:00
- å ´æ‰€ï¼š
- ã‚ªãƒ³ã‚µã‚¤ãƒˆä¼šå ´: è²¸ã—ä¼šè­°å®¤ (æ±äº¬éƒ½æ¿æ©‹åŒºå‰é‡ç”º3-41-1)
  - äººæ•°åˆ¶é™ãŒã‚ã‚‹ãŸã‚ã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å‚åŠ ã‚’å¸Œæœ›ã™ã‚‹æ–¹ã¯ Slack ã«ã¦ã”é€£çµ¡ãã ã•ã„
  - æ„ŸæŸ“ç—‡å¯¾ç­–ã«ã”å”åŠ›ãã ã•ã„ã€‚
  - ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ä¼šå ´:
    - Discord: `Pitagora / Workflow Meetup Japan` ã‚µãƒ¼ãƒ

## å•ã„åˆã‚ã›

- å¹¹äº‹: å¤§ç”° `tazro.ohta [at] chiba-u.jp`

## ã‚¿ã‚¤ãƒ ãƒ†ãƒ¼ãƒ–ãƒ«

é€”ä¸­å‚åŠ ã€é€”ä¸­é€€å‡ºã¯è‡ªç”±ã§ã™ã€‚åˆã‚ã¦å‚åŠ ã•ã‚Œã‚‹æ–¹ã¯ãœã² [éã”ã—æ–¹ã‚¬ã‚¤ãƒ‰](/events/meetup/whatis) ã‚’ã”è¦§ãã ã•ã„ã€‚

|    Time     |                        |
| :---------: | :--------------------: |
| 13:00-13:15 |     ä»Šæ—¥ã®ä½œæ¥­ç¢ºèª     |
| 13:15-17:00 | é–‹ç™ºã¨ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ |
| 17:00-18:00 |      ãƒ©ãƒƒãƒ—ã‚¢ãƒƒãƒ—      |
|   18:00-    |       æœ‰è­˜è€…ä¼šè­°       |

## ãƒŸãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã®ä¸»æ—¨

- ãƒ‡ãƒ¼ã‚¿è§£æãƒ„ãƒ¼ãƒ«ãƒ»ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å…±æœ‰ã™ã‚‹
  - ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚’ã‚³ãƒ³ãƒ†ãƒŠåŒ–ã™ã‚‹
  - Galaxy ã‚„ CWL ãªã©ã‚’ä½¿ã£ã¦ãƒ„ãƒ¼ãƒ«å®šç¾©ã€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®šç¾©ã‚’æ›¸ã
  - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ›¸ã„ã¦ GitHub ã§å…¬é–‹ã™ã‚‹
- å…±æœ‰ã•ã‚ŒãŸãƒ„ãƒ¼ãƒ«ã‚„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œã™ã‚‹
  - ã†ã¾ãã„ã£ãŸã“ã¨ã€ã†ã¾ãã„ã‹ãªã‹ã£ãŸã“ã¨ã‚’è¨˜éŒ²ã™ã‚‹
- æŠ€è¡“æƒ…å ±ã‚’å…±æœ‰ã™ã‚‹
  - SNS ã« post ã™ã‚‹
  - ãƒ–ãƒ­ã‚°ã‚’æ›¸ã
- é–¢é€£OSSãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ã‚³ãƒŸãƒƒãƒˆã™ã‚‹
  - SNSã§è³ªå•ã™ã‚‹
  - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã® Gitter channel ãŒã‚ã‚Œã°ãã“ã§èã
  - Issueã‚’ç«‹ã¦ã‚‹
  - Pull Request ã‚’é€ã‚‹
- ãã®ä»–ãƒ‡ãƒ¼ã‚¿è§£æã«é–¢ã‚ã‚‹äººã€…ã®æ—¥ã€…ã®æš®ã‚‰ã—ãŒè±Šã‹ã«ãªã‚‹é–‹ç™ºã‚’é€²ã‚ã‚‹

## ã¾ã¨ã‚

### å¤§ç”°

- Llama2 via `transformers` on Jupyter Notebook in Docker container on a local machine with NVIDIA GPU ã‚’ã‚„ã‚‹
  - ã‹ã¤ã¦ã¯ nvdia-docker ã¨ã‹ã„ã‚ã„ã‚ã‚ã£ãŸã‘ã©ä»Šã¯ [nvidia-container-toolkit](https://github.com/NVIDIA/nvidia-container-toolkit) ã‚’ä½¿ã†ã¨ã„ã†ã“ã¨ã‚‰ã—ã„
    - [å‚è€ƒ](https://medium.com/nvidiajapan/nvidia-docker-%E3%81%A3%E3%81%A6%E4%BB%8A%E3%81%A9%E3%81%86%E3%81%AA%E3%81%A3%E3%81%A6%E3%82%8B%E3%81%AE-20-09-%E7%89%88-558fae883f44) 2020å¹´ã®è¨˜äº‹ã§æ—¢ã«å¤ã„ãŒæ­´å²ãŒæ›¸ã„ã¦ã‚ã‚‹
    - [installation guide](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html)
  - CUDA Toolkit ã¯ã„ã‚‰ãªã„ã‘ã© NVIDIA driver ã¯ã‚¤ãƒ³ã‚¹ã‚³ã—ã¦ãªã„ã¨ã ã‚ã ã‚ˆã¨ã®ã“ã¨
    - apt ã§å…¥ã‚‹[ã¨ã®ã“ã¨](https://docs.nvidia.com/datacenter/tesla/tesla-installation-notes/index.html#ubuntu-lts)
  - å‚è€ƒ:
    - [GPU ãŒä½¿ãˆã‚‹ Jupyter Notebook ç’°å¢ƒã‚’æœ€é€Ÿã§ç”¨æ„ã™ã‚‹](https://qiita.com/kaijism/items/ada49192df0a6d285c3a)
    - [Ubuntu20.04LTS + docker + tensorflow(GPU) + jupyter notebook ã§ç’°å¢ƒæ§‹ç¯‰](https://qiita.com/mizuhugu35/items/31dcbb1600d2e77c5d13)
- èº«ã®å›ã‚Šã®GPUè¼‰ã£ã¦ã‚‹ãƒã‚·ãƒ³ã‚’èª¿æŸ»
  - å¤§å­¦ã®ã‚µãƒ¼ãƒå®¤ã®ãƒã‚·ãƒ³ã« RTX 6000 ada ãŒè¼‰ã£ã¦ã„ã‚‹
  - ãƒ©ãƒœã®å…±ç”¨ã‚¯ãƒ©ã‚¹ã‚¿ã®GPUãƒãƒ¼ãƒ‰ã« A40 ãŒ 4å°åˆºã•ã£ã¦ã„ã‚‹
  - éºä¼ç ”ã® V100 4æšåˆºã— GPU ãƒãƒ¼ãƒ‰ã‚’å€Ÿã‚Šã‚‹ã“ã¨ã«ãªã£ã¦ã„ã‚‹

#### ãƒ­ã‚°

- WS ã«æ§‹ç¯‰
- nvidia driver ã‚’ç¢ºèª
- ä½•ã‚‚å…¥ã£ã¦ãªã„ã®ã§ curl docker ã‚’å…¥ã‚Œã‚‹ ([å‚è€ƒ](https://docs.docker.com/engine/install/ubuntu/))
- nvidia-container-toolkit ã‚’å…¥ã‚Œã‚‹ ([å‚è€ƒ](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#installing-with-apt))

```
$ nvidia-smi
Wed Jan 10 23:29:35 2024
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.85.05    Driver Version: 525.85.05    CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA RTX 6000...  On   | 00000000:2D:00.0 Off |                  Off |
| 30%   27C    P8     3W / 300W |     82MiB / 49140MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1333      G   /usr/lib/xorg/Xorg                 63MiB |
|    0   N/A  N/A      1480      G   /usr/bin/gnome-shell               16MiB |
+-----------------------------------------------------------------------------+
$ sudo apt update -y && apt install -y curl
$ curl -fsSL https://get.docker.com -o get-docker.sh
$ sudo sh ./get-docker.sh
$ sudo usermod -aG docker $USER
$ docker info
$ curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \
  && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
$ sudo apt-get update -y
$ sudo apt-get install -y nvidia-container-toolkit
$ sudo docker run --rm --gpus all nvidia/cuda:12.0.0-base-ubuntu20.04 nvidia-smi
docker: Error response from daemon: could not select device driver "" with capabilities: [[gpu]].
```

- ã ã‚ã˜ã‚ƒã‚“ï¼ã¨æ€ã£ãŸã‚‰ nvidia container toolkit ã‚’å…¥ã‚ŒãŸã‚ã¨ dockerd ã‚’å†èµ·å‹•ã—ãªã„ã¨ã ã‚ã£ã½ã„ã€‚
- [jupyter/pytorch-notebook](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-pytorch-notebook) ã¨ã„ã†ã„ã„æ„Ÿã˜ã®ã‚³ãƒ³ãƒ†ãƒŠãŒã‚ã£ãŸ

```
$ sudo service docker restart
$ docker run --rm --gpus all quay.io/jupyter/pytorch-notebook:2024-01-08 nvidia-smi
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.85.05    Driver Version: 525.85.05    CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA RTX 6000...  On   | 00000000:2D:00.0 Off |                  Off |
| 30%   27C    P8     2W / 300W |     82MiB / 49140MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
+-----------------------------------------------------------------------------+
$ docker run -d --name nb -p 8888:8888 --rm --gpus all quay.io/jupyter/pytorch-notebook:2024-01-08
```

- port forward ã—ã¦ãƒ­ãƒ¼ã‚«ãƒ«ã§ notebook å©ã‘ãŸã€ãƒ¨ã‚·ï¼

```
$ docker run --rm -it --gpus all quay.io/jupyter/pytorch-notebook:2024-01-08 bash
$ python3
>>> import torch; torch.cuda.is_available()
False
```

- ã¨æ€ã£ãŸã‚‰ notebook ä¸Šã® torch ãŒGPUã‚’èªè­˜ã—ã¦ã„ãªã„
  - ãƒ­ãƒ¼ã‚«ãƒ«ã§ã¯å‹•ã + nvidia-smi ã¯å‹•ãã®ã§ jupyter/pytorch ã‚³ãƒ³ãƒ†ãƒŠå†…ã® cuda version ã®å•é¡Œã¨æ€ã‚ã‚Œã‚‹
  - ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ã®ã¯å¾®å¦™ã«ã‚ã‚“ã©ãã•ãã†ãªæ°—ãŒã™ã‚‹ã€‚ã€‚
- ç‰©ç†GPUã¨ãƒã‚¤ãƒ†ã‚£ãƒ– nvidia driver ã¨ã‚³ãƒ³ãƒ‘ãƒãª cuda ã®nvidiaå…¬å¼ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’æŒã£ã¦ãã¦ã€ãã“ã« jupyter ç­‰ã€…ã‚’ï½²ï¾ï½½ï½ºã—ã¦ã„ãæ–¹å‘ã§

```
$ cat Dockerfile
FROM nvidia/cuda:12.0.0-base-ubuntu20.04

USER root

COPY ./requirements.txt /tmp
WORKDIR /code

RUN apt update -y && apt upgrade -y && apt install -y curl python3 python3-distutils
RUN curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py && python3 get-pip.py

RUN pip install -r /tmp/requirements.txt
$ cat requirements.txt
jupyter
jupyterlab
numpy
pandas
matplotlib
scikit-learn
scikit-image
scipy
torch
torchvision
transformers
$ docker build . -t  gpu-notebook:20240111
$ docker run --rm -it --gpus all gpu-notebook:20240111 bash
$ python3
>>> import torch; torch.cuda.is_available()
True
```

todo

- notebook ä¸Šã‹ã‚‰ gpu å©ã‘ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
- torch ã§ gpu å©ã‘ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
- huggingface ã§ llama2 ã®ãƒ¢ãƒ‡ãƒ«ã‚’è½ã¨ã—ã¦ãã‚‹
- llama2 ã‚’ notebook ã§å©ã

### éœ²å´

- å¤§ç›®æ¨™
  - PyTorch Ã— GPUã§æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒªãƒ³ã‚°
  - â†’ Pythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸é–‹ç™º
  - â†’ å…±åŒç ”ç©¶ã«å¿œç”¨ï¼ˆãƒ¡ã‚¿ãƒœãƒ­ãƒ¼ãƒ ã€æ‚£è€…ãƒ‡ãƒ¼ã‚¿ç­‰ï¼‰
- ä¸­ç›®æ¨™
  - ãã®ãŸã‚ã®GPUç’°å¢ƒã‚’æ•´å‚™ï¼ˆ2å°ã‚ã‚‹ï¼‰
  - ä»¥ä¸‹ã‚’å‹•ä½œã•ã›ãŸã„
  ```
  python -c "import torch; print(torch.cuda.is_available()); print(torch.cuda.current_device()); print(torch.cuda.device_count())"
  ```
  - cf. ã†ã¾ãã„ã‹ãªã„ã¨ãã®ã‚¨ãƒ©ãƒ¼
  ```
  Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/koki/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/cuda/__init__.py", line 769, in current_device
    _lazy_init()
  File "/home/koki/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/cuda/__init__.py", line 289, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
  AssertionError: Torch not compiled with CUDA enabled
  ```
  - [to()ãƒ¡ã‚½ãƒƒãƒ‰](https://atmarkit.itmedia.co.jp/ait/articles/2008/28/news030.html)ã§CPU â†’ GPUã«åˆ‡ã‚Šæ›¿ãˆã¦ã€è¨ˆç®—ãŒé«˜é€Ÿã«ãªã‚‹ã®ã‚’ä½“æ„Ÿã—ãŸã„
- æ–¹é‡
  - ä»®æƒ³ç’°å¢ƒã§å°‘ã—ã§ã‚‚å†ç¾æ€§ã®ã‚ã‚‹ç’°å¢ƒæ§‹ç¯‰ï¼ˆ`mamba`ã€ã‚‚ã—ãã¯`virtualenv`ï¼‰
- å¿…è¦ãªã‚‚ã®
  1. **NVIDIA driver**ï¼ˆæœ€åˆã‹ã‚‰å…¥ã£ã¦ãŸã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒå¤§äº‹ã‚‰ã—ã„ï¼‰
  - ç¢ºèªæ–¹æ³•: `nvidia-smi`
  ```
  Thu Jan 11 14:17:21 2024
  +---------------------------------------------------------------------------------------+
  | NVIDIA-SMI 535.86.10              Driver Version: 535.86.10    CUDA Version: 12.2     |
  |-----------------------------------------+----------------------+----------------------+
  ...
  ```
  2. **CUDA**ï¼ˆæœ€åˆã‹ã‚‰å…¥ã£ã¦ãŸã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒå¤§äº‹ã‚‰ã—ã„ï¼‰
  - ç¢ºèªæ–¹æ³•: `nvcc -V`
  ```
  nvcc: NVIDIA (R) Cuda compiler driver
  Copyright (c) 2005-2023 NVIDIA Corporation
  Built on Tue_Jun_13_19:16:58_PDT_2023
  Cuda compilation tools, release 12.2, V12.2.91
  Build cuda_12.2.r12.2/compiler.32965470_0
  ```
  3. **Python**ï¼ˆ3.11ï¼‰
  4. **Pythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸**
  - _Conda-forgeç³»_: tensorboard, pandas, matplotlib, python-graphviz, pot
  - _Anacondaç³»_: jupyterlab
  - _PyTorchç³»_: pytorch, torchvision, torchaudio
  - _NVIDIAç³»_: pytorch-cuda
- ~~èª²é¡Œ~~ï¼ˆä»Šæ—¥è§£æ±ºã—ãŸï¼‰
  - `mamba create`ã§ã¾ã¨ã‚ã¦ãƒ„ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã‚ˆã†ã¨ã™ã‚‹ã¨1æ—¥ãŒã‹ã‚Šï¼ˆãƒãƒ£ãƒ³ãƒãƒ«æ•°ãŒå¤šã„ã›ã„ï¼Ÿ[ã‚­ãƒ£ãƒƒã‚·ãƒ¥](https://weblabo.oscasierra.net/python-anaconda-clean/)ãŒæºœã¾ã£ã¦ã‚‹ï¼Ÿï¼‰
  ```
  mamba create -n pytorch python=3.11 pytorch torchvision torchaudio tensorboard pandas matplotlib jupyterlab python-graphviz pot -c conda-forge -c anaconda -c pytorch -c nvidia -y
  ```
  - ä»¥ä¸‹ã¯å‹•ãï¼ˆæœ€å°é™ã®æ§‹æˆï¼‰
  ```
  mamba create -n test pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia -y
  ```
  - pytorch-cudaã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ãƒŸã‚¹ã£ã¦å‡ºãŸã‚¨ãƒ©ãƒ¼
  ```
  Could not solve for environment specs
  The following package could not be installed
  â””â”€ pytorch-cuda 12.2**  does not exist (perhaps a typo or a missing channel).
  ```
- ã‚ã‹ã£ãŸã“ã¨
  1. ç°¡ç´ ã«`mamba create` â†’ ãã®ä¸­ã§`mamba install`ã®æ–¹ãŒæ—©ã„
  ```
  conda activate test
  mamba install -c conda-forge tensorboard -y
  mamba install -c conda-forge pandas -y
  mamba install -c conda-forge matplotlib -y
  mamba install -c anaconda jupyterlab -y
  mamba install -c conda-forge python-graphviz -y
  mamba install -c conda-forge pot -y
  ```
  2. æœ€åˆã‹ã‚‰[æœ¬å®¶ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://pytorch.org/get-started/previous-versions/)ã‚’å‚ç…§ã™ã¹ã—ï¼ˆå€‹äººãƒ–ãƒ­ã‚°ã®æƒ…å ±ã¯ãƒã‚¤ã‚ºãŒå¤šã„ï¼‰

### æ± ç”°

- apache sparkã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ä¸Šã§å®Ÿè¡Œã™ã‚‹ãŸã‚

  - hadoopã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’ã²ãŸã™ã‚‰å®Ÿè¡Œã—ã¦ã„ã¾ã—ãŸ
  - ã„ã‚ã„ã‚é›£ã—ã„...

  è¶…é«˜é€Ÿãªãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ãŒã‚ã‚Œã°ã€HDFSã‚’åˆ©ç”¨ã—ãªãã¦ã‚‚å…±æœ‰ãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾ã—ã¦sparkã‚’å®Ÿè¡Œã™ã‚Œã°ã‚ˆã„ã‚ˆ(éºä¼ç ”ã§ã¯ãã†ã—ã¦ã„ã‚‹[ä¸¹ç”Ÿ])

### é‚£é ˆé‡

- å…ˆæœˆMeetupã§è©¦ã—ãŸ kubespray.io ã®ãŠã•ã‚‰ã„
- RIKEN-RCCSã® [WHEEL](https://github.com/RIKEN-RCCS/WHEEL) ï¼ˆWebãƒ™ãƒ¼ã‚¹ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ„ãƒ¼ãƒ«ï¼‰ã‚’ K8s ã«ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¦ã¿ãŸã„ï¼
  - WHEELã‚µãƒ¼ãƒã‹ã‚‰ãƒªãƒ¢ãƒ¼ãƒˆã®è¨ˆç®—è³‡æºï¼ˆã‚¸ãƒ§ãƒ–å®Ÿè¡Œç’°å¢ƒï¼‰ã¸ã¯ã€å…¥å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã¯rsyncã§è»¢é€ã€sshã§ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œã™ã‚‹ã‚·ãƒ³ãƒ—ãƒ«ãªä»•çµ„ã¿
  - å¯Œå²³ã®Open OnDemandç’°å¢ƒã§ã¯ã€Singularityã‚³ãƒ³ãƒ†ãƒŠã§WHEELãŒèµ·å‹•ã™ã‚‹æ–¹å¼ã§é‹ç”¨ã—ã¦ã„ã‚‹ã‚‰ã—ã„

### ç¦äº•

- ä»•äº‹ã‚’ã—ãŸ
- [`tataki`](https://github.com/sapporo-wes/tataki) :ã€€ãƒã‚¤ã‚ªã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’åˆ¤å®šã™ã‚‹ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ãƒ„ãƒ¼ãƒ«ã€‚(i.e. `hoge.fa`ã¯æœ¬å½“ã«FASTAãªã®ã‹ã€ã‚’èª¿ã¹ã‚‹)
  - [`tataki`](https://github.com/sapporo-wes/tataki)ã®ä»•æ§˜ã‚’discussionã—ãŸ
    - è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« (`tataki.conf`) ã®æ›¸ãæ–¹
    - å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    - [edamontology](https://github.com/edamontology/edamontology/releases)å†…ã®`EDAM_1.25.csv`ã‚’æ”¹å¤‰ã—ã¦`tataki`å´ã«çµ„ã¿è¾¼ã‚€éš›ã®ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã‚’ç¢ºèªã€‚[`CC BY-SA 4.0 DEED`](https://creativecommons.org/licenses/by-sa/4.0/deed.en)ã®`ShareAlike`ã‚ã‚‹ã‘ã©å¼•ç”¨ã‚’ã¡ã‚ƒã‚“ã¨è¨˜è¿°ã™ã‚Œã°å¤§ä¸ˆå¤«ãã†ã€‚

### æœ«ç«¹

- Sapporo ã® RO-Crate æ©Ÿèƒ½ã« MultiQC ã‚’çµ±åˆ
  - Tonkaz ã®æ¯”è¼ƒã« MultiQC Report ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã†
- workflow input parameter ã® schema ã‚’ jsonschema ã§æ›¸ã‹ã›ã‚ˆã†å•é¡Œ
  - ç¾çŠ¶ cwltool --make-template ã§ template ã¯å‡ºã¦ãã‚‹ãŒã€åƒ•çš„ã«ã»ã—ã„ã®ã¯ template ã§ã¯ãªã schema
  - tanjo-san ã«ã„ãã¤ã‹ test ã«ä½¿ãˆãã†ãª cwl file ã® eg ã‚’ã‚‚ã‚‰ã£ãŸ
    - å®šç¾©è‡ªä½“ãŒæ„åœ°æ‚ªãªã‚±ãƒ¼ã‚¹:
      - https://github.com/common-workflow-language/cwl-v1.2/blob/main/tests/echo-tool-packed.cwl
      - https://github.com/common-workflow-language/cwl-v1.2/blob/main/tests/revsort-packed.cwl
    - å‹ãŒæ„åœ°æ‚ªãªã‚±ãƒ¼ã‚¹:
      - https://github.com/common-workflow-language/cwl-v1.2/blob/main/tests/anon_enum_inside_array.cwl
    - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå°‘ã—å¤šãã¦ã€å®šç¾©ãã®ã‚‚ã®ã¯ç´ ç›´ãªã‚±ãƒ¼ã‚¹
      - https://github.com/common-workflow-language/cwl-v1.2/blob/main/tests/bwa-mem-tool.cwl
    - CommandInputParameter ãŒçŸ­ç¸®å½¢ (e.g., param: string) ã«ãªã£ã¦ã„ã‚‹ã‚±ãƒ¼ã‚¹
      - https://github.com/common-workflow-language/cwl-v1.2/blob/main/tests/env-tool1.cwl
    - å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãªã—
      - https://github.com/common-workflow-language/cwl-v1.2/blob/main/tests/envvar3.cwl
    - Any
      - https://github.com/common-workflow-language/cwl-v1.2/blob/main/tests/params.cwl
  - cwl-utils ã« PR ã‚’ã¤ãã£ã¦ã¿ã‚‹

### ä¸¹ç”Ÿ

- CWL v1.2.1 ãŒ[ãƒªãƒªãƒ¼ã‚¹ã•ã‚ŒãŸ](https://github.com/common-workflow-language/cwl-v1.2/releases/tag/v1.2.1)
  - å…¬å¼ã®ã‚¢ãƒŠã‚¦ãƒ³ã‚¹ãŒ [X](https://twitter.com/commonwl) ã‹ã‚‰ Mastodon ([floss.social](https://floss.social/@cwl)) ã«ç§»è¡Œã—ãŸãŸã‚ã€X ã ã‘ã ã¨ç™ºè¦‹ã§ããªã„
- éºä¼ç ”å†…ã§ã€rootless podman å…¨é¢å°å…¥ã§ããªã„ã®ï¼Ÿã¨ã„ã†ãƒã‚¿æŒ¯ã‚Šã‚’ã—ãŸ
  - rootless, daemonless, SIF ã‚‚å‹•ã
  - ã“ã‚Œã§ã„ã„ã®ã§ã¯ï¼Ÿ
- è«–æ–‡ã®æ§‹æˆã‚’è€ƒãˆã¦ã„ãŸ

  - ç´ æ•µãªã‚¿ã‚¤ãƒˆãƒ«ã‚’è€ƒãˆã‚‹åŠ›ãŒã»ã—ã„

- [Kubernetes in Rootless Podman.pdf](https://github.com/AkihiroSuda/AkihiroSuda/blob/master/slides/2023/20231116%20%5BPodman%20Special%20Event%5D%20Kubernetes%20in%20Rootless%20Podman.pdf)ã€€ä½•ã‹èª­ã‚‚ã†ã¨æ€ã£ã¦æ”¾ç½®ã—ã¦ãŸé–¢é€£è³‡æ–™ã‚ã‚‹ã®ã§ã‚·ã‚§ã‚¢ã—ã¾ã™ã€€byã€€ç¦äº•

### å±±æœ¬

- å¤§ããªç›®çš„
  - [NCGM-genome/WGSpipeline](https://github.com/NCGM-genome/WGSpipeline/tree/cwl-to-nf)ã‚’Nextflowã«å¤‰æ›
- å°ã•ãªç›®çš„
  - 1stepï¼ˆprocessï¼‰ã‚’Nextflowã«å¤‰æ›
- CWLã®ã‚³ãƒ¼ãƒ‰ã‚’Nextflowã«å¤‰æ›
  - å¤‰æ›å¯¾è±¡ã®CWLã«ã¤ã„ã¦æ•´ç†âœ…
    - GitHub
      - [NCGM-genome/WGSpipeline](https://github.com/NCGM-genome/WGSpipeline/tree/cwl-to-nf)
    - ã‚³ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«
      - Workflows/germline-gpu.cwl
      - â‘ Tools/pbrun-fq2cram-multiRGs.cwl
      - â‘¡Tools/pbrun-haplotypecaller-from-cram.cwl
    - stepsæ•°ï¼ˆprocessæ•°ï¼‰
      - 1. Fq2Cramï¼šâ‘ ã®Toolä½¿ç”¨
      - 2. haplotypecaller_autosomeï¼šâ‘¡ã®Toolä½¿ç”¨
      - 3. haplotypecaller_PARï¼šâ‘¡ã®Toolä½¿ç”¨
      - 4. haplotypecaller_chrX_femaleï¼šâ‘¡ã®Toolä½¿ç”¨
      - 5. haplotypecaller_chrX_maleï¼šâ‘¡ã®Toolä½¿ç”¨
      - 6. haplotypecaller_chrYï¼šâ‘¡ã®Toolä½¿ç”¨
    - å…¥åŠ›æƒ…å ±
      - [ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°](https://github.com/NCGM-genome/WGSpipeline/tree/cwl-to-nf?tab=readme-ov-file#tutorial-1-run--germline-gpucwl-workflow-with-a-pair-of-fastq-files)
      - arguments
    - ã‚³ãƒ³ãƒ†ãƒŠï¼ˆsingularityã‚³ãƒãƒ³ãƒ‰ã§å®Ÿè¡Œï¼‰
      - â‘ ã®Toolï¼šhacchy/pbrun-fq2bam:4.0.0-1_v20230412
      - â‘¡ã®Toolï¼šnvcr.io/nvidia/clara/clara-parabricks:4.0.0-1
    - ãƒã‚·ãƒ³ã®è¨­å®š
      - hints:ã§CUDAã®æ¡ä»¶ã‚’æŒ‡å®šã—ã¦ã„ã‚‹
  - ç†è§£ã—ãŸã“ã¨âœ…
    - .nfã¨nextflow.configã‚’ç”¨æ„
    - .nfã®processæ•°ã¯6ã¤
    - nextflow.configã§å…¥åŠ›æƒ…å ±ã€singularityã®æŒ‡å®šã€ã‚³ãƒ³ãƒ†ãƒŠã®ãƒªãƒã‚¸ãƒˆãƒªã‚’æŒ‡å®š
  - ã‚ã‹ã‚‰ãªã„ã“ã¨âœ…
    - å…¥åŠ›å€¤
      - paramsã®æ›¸ãæ–¹
      - ã‚³ãƒ³ãƒ†ãƒŠ
        - singularityã®æŒ‡å®šã®ä»•æ–¹ï¼ˆãƒªãƒã‚¸ãƒˆãƒªã¯DockerHub
      - ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
        - Nextflowã®workflowãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆå‡¦ç†ã®å®Ÿè¡Œé †ï¼‰ã®æ›¸ãæ–¹
  - Nextflowã®å…¬å¼Documentã‚’èª­ã‚€ğŸƒ
    - https://www.nextflow.io/docs/latest
  - Nextflowã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã«å–ã‚Šçµ„ã‚€
    - https://training.nextflow.io/basic_training
  - ã‚ã‹ã‚‰ãªã„ã“ã¨ã‚’å†è€ƒ
  - 1stepï¼ˆprocessï¼‰ã‚’Nextflowã«å¤‰æ›
    - Fq2Cramã®stepã‚’å¤‰æ›
- ãƒ¡ãƒ¢
  - (by suecharo) æ˜”è€ƒãˆãŸã“ã¨ã‚ã‚Šã¾ã™ã‘ã©ã€LLM ã«é£Ÿã‚ã›ã¦å¤‰æ›ã•ã›ã¦ã€ã‹ã¤å¤‰æ›ãŒã¡ã‚ƒã‚“ã¨å‡ºæ¥ã¦ã„ã‚‹ã‹ã‚’ç¢ºèªã™ã‚‹ãŸã‚ã® test ã‚’ç”¨æ„ã—ãŸã»ã†ãŒæ¥½ã ã£ãŸã¨æ€ã„ã¾ã™
    - (by yamaken)ãŸã—ã‹ã«ã€LLMã«é£Ÿã‚ã›ã¦å¤‰æ›ã¯ã‚„ã£ã¦ã„ã¾ã—ãŸãŒï¼ˆã†ã¾ãã„ã‹ãªã‹ã£ãŸï¼‰ã€ãƒ†ã‚¹ãƒˆã‚’è‡ªå‰ã§ç”¨æ„ã™ã‚‹ã®ã¯ã—ã¦ãªã‹ã£ãŸã€‚
  - Nextflowã«ã¤ã„ã¦ã®é•å’Œæ„Ÿï¼šinput outputã®ä¾å­˜é–¢ä¿‚ã§å‡¦ç†ã®é †ç•ªæ±ºã‚ã¦ã‚ˆã•ãã†ãªã®ã«ã€ã€Œworkflowã€ã§å®šç¾©ã—ãªã„ã¨ã„ã‘ãªã„ã¨ã“ã‚
- ä½™è«‡
  - å¹´æœ«ã«å‰¯é¼»è…”ç‚ã®æ‰‹è¡“ã—ãŸã€‚é¼»è©°ã¾ã‚Šã«æ‚©ã¾ã•ã‚Œã¦ã„ã‚‹äººã¯ãŠã™ã™ã‚ã§ã™ã€‚
